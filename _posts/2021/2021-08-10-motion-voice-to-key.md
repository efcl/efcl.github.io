---
title: "体の動きや音声入力でアプリケーションをハンズフリー操作したりプログラミングする"
author: azu
layout: post
date : 2021-08-10T23:31
category: 雑記
tags:
    - software

---

この記事は、体の動きとか音声入力でアプリケーションを操作したり、プログラミングをするにはどうすればいいかということをいろいろ実験してみた記事です。
この記事には、実用性があるものと現実的に使うにはトレーニングが必要なものが混在しています。そのため、そこまで期待してはいけません。

この記事は、[Talon](https://talonvoice.com/)と[macOSの音声入力](https://support.apple.com/ja-jp/guide/mac-help/mh40584/mac)で書いたものを手作業で修正しています。

## きっかけ

この記事を書いたきっかけは、t_wadaさんが老眼について書いていたがきっかけの一つです。

<blockquote class="twitter-tweet"><p lang="ja" dir="ltr">プログラマ35歳定年説はとっくに過去のもので、35歳を過ぎても能力も報酬も伸び続けるし、生涯現役プログラマのロールモデルとなる方も増えてきた。ただ諸先輩方から聞いた話をまとめると、ベテランプログラマの前に立ち塞がるのは「老眼」で、こればかりは本当に恐ろしい。何か対策はあるだろうか……</p>&mdash; Takuto Wada (@t_wada) <a href="https://twitter.com/t_wada/status/1217979511892934657?ref_src=twsrc%5Etfw">January 17, 2020</a></blockquote>

<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script> 

人間が長時間プログラミングしたりPCを触ったりするには単一障害点となる体の部位(頭、目、指、手首、肩、腰など)が結構多くて その単一障害点をどうやって乗り越えるかっていうのに昔から興味がありました。
この中で手を使わない方法でキーを入力する方法って何があるかなぁって思って、それを少し実装したり音声の場合はTalonって言うソフトを使ってできるのかを調査したって感じの記事です。

また、[何を作るとより良くなるかなと考えていて](https://twitter.com/azu_re/status/1413798002708271104)、今[コントロールできてないものをコントロールできるようにする](https://twitter.com/azu_re/status/1413798739370672129)と何かしらの飛躍があるのかなと思いました。
今、主に手でコードを書いたりしていますが、音声入力とか体の動きを入力できたらできることが増えないかなと考えたのもきっかけの一つです。

## 体の動き to キー入力

まずまずはあぁGoogleストリートビューを体のモーションで動かすって言うアプリを昔描いていてこれを応用してどのアプリケーションでも同じように体の動きが気に旅行できるって言うアプリケーションを作ってみることしました。

技術的にはウェブカメラの映像をメディアストリームAPIで取得して仮想のサブピクセル1から1ってなピクセル家を超えると金入力として扱うって言う仕組みにしています。
tensorflow.js使ってサムズアップとか指の動きジェスチャーに対する筋力も一応サポートしてます。

この仕組みだとずっとキー入力をし続けるような操作に対しても結構有効に動いて、たまに間違ったときにジェスチャーでバックしたりみたいな感じの処理をできる。
具体的にはこのアプリ使ってKindleで本を読んだりとか漫画読んだりみたいなずっとページめくりもしてるようなアプリ消したとまぁまぁ使いたくなって感じでした。

- [azu/motion-key: A keyboard config app for your motion.](https://github.com/azu/motion-key)

[(12) azu on Twitter: "コントロールできないものをコントロール可能にするというのが近いのかな" / Twitter](https://twitter.com/azu_re/status/1413798739370672129)
[(12) azu on Twitter: "気をつけてもどうにもならないものって何があるんだろ？ それを解決していくのが良い感じがしてきた" / Twitter](https://twitter.com/azu_re/status/1413798002708271104)

使ってみるとまぁわかるともん助戸体動きは細かい制御が向いてないんでなんか大雑把全身的なやつだといいんですけど後動いてなくちゃいけないんで結構疲れるって言うものがあるのがわかりました。

## 音声 to キー入力

音声入力をしたら記録をするって言うのを同じように作ろうかなって思ったんですけど先音声周りは結構普通アプリケーションが充実してそうな気がしたんでちょっと探してみたらタロンとかいくつか使えそうなアプリケーションがあったのでそれを触ってみることにしました.

出てみると実際にプログラミングを音声でやる場合には次の2つのソフトがよく使われている感じでした。

- [Talon](https://talonvoice.com/)
- [Serenade | Code with voice](https://serenade.ai/)


こういった音声アクセシビリティー的な感じなアプリケーションでロフクリーンローブの理論と同じように健全な所でも全然役に立つ機能がいっぱいあるんでそれをちょっと掘ってみ。

こういった音声入力系のアプリケーションが充実していくと、そのようなアプリケーションがないと困る人以外にもそのアプリケーションのメリットを享受しやすくなっていると思います。
問えば今尻とかGoogleとかアレクサとかの音声入力のデバイスを持っている人いっぱいいるんでそれを使って音声入力するってのも結構楽なんで普通に雲手が使えない人じゃない場合でも音声入力できるようになるってのは良い。
この特定の問題に困っている人以外にもメリットを享受する集まり誰もがメリット享受するようなやつの効果はカーブカット効果って言われてるやつがかなり近いものだと思っています。

- [社会の全員がラクになる―「カーブカット効果」のこと｜渡邉文隆 | ファンドレイザー｜note](https://note.com/fwatanabe/n/n1da8ab2849cd)

実際にTalonを使って間音声入力は英語用の雲学習データしかないんでちょっと厳しいですけど音声コマンドとしては結構PythonでCode書いて音声コマンドを実装できるになっているんでかなり便利な感じでした。

どっち入力自体はそのMacOSの音声入力って言う子ママの機能があるんでTalonでWake Upキーワードを叩くとこの音声入力を起動して音声入力が終わったら改行するみたいな仕組みを音声コマンドを実装してこの記事は書いてます。

Talonにはへぇーただ破裂音とか 家の音声認識もあるんで英語以外にもﾊﾟッとかｼｭみたいな音声もコマンドとして使えます。
実際に自分はﾊﾟッを改行に割り当てて記事を書いたりしています。

声認識したよあぁ8割9割位は普通に認識するので難しい単語とか使わなければ、 まぁまぁ普通に入力できるかなって気がします。

## Talonの使い方

## Talonの設定

## Talonの感想

で実際にTalonを使ってKindleで本を読むみたいなことをやっていてお稽古を これは普通に使いやすいです。
音声コマンドでネクストって言うと次のページに行ってバックって言うと前のページに行ったりすることができてて、
Talonの場合は音声コマンドがスタックできるのでNextNextNextって言えばでは3回Nextのキー押せるみたいなことができるんで 手でめくるようにいける。

音声入力なんで普通に体動かしながらページめくったりできて、手を使わなくても音声でページがめくれるっていうのは結構快適な気がしました。
自分の場合はシェイプエイトって言うトランポリンを最近買ったのでこれで跳ねながらネクストでKindleをよんでいることが増えてます

イマイチなところはWake UpキーワードとかにTalon WakeとかTalon Sleepとか、Input modeとかでモード切り替えしたりしているのですが、
結構雑音でこれが反応しちゃうことがあるので、Sleepにしちゃう気がします。
(SleepからもWakeupキーワードで起動はできたりもしますが、雑音がWakeupキーワードになったりすることがあるので工夫が必要)

破裂音とかは結構音声コマンドとしての未来を感じていて、
キーボードでも記号が足りなくなる問題がありますが、破裂音は結構種類が多いのでトレーニングするとショートカットが色々増やせるようになるんじゃないかなって気がしました。
あと、音声コマンドはショートカットと違ってキーのくみあわせを覚えなくてもいいので、記憶しやすいという特徴もあります。

あとTalonはローカルで音声認識をしているため、反応が数百msぐらいで反応が返ってくる事が多いのでレスポンスが良いです。
Hey SiriとかOK Googleみたいなのは、反応が返ってくるまで数秒とかかかっていて、そこがストレスになる気がしています。(VUI的には)

TalonはUDPみたいな感じで、一方通行で音声を入れていくとそれをそのままコマンドにするって感じなので、
常時音声入力できているTalonは誤検知がうまく減らせればかなり有用だなーって気がします。

## まとめ

人がプログラミングするには目とか手とかいろんなパーツが動かすことがひつようになるのですが、今はアプリケーションで少し負担を減らせるようなものがあるような感じがしました。
実際に使いこなすにはある程度のトレーニングは必要ですが、逆をいればトレーニングすれば使えるレベルのものがで来ている感じです。(音声認識自体もトレーニングしたデータを使う)

- [Coding with voice dictation using Talon Voice](https://www.joshwcomeau.com/blog/hands-free-coding/)

音声スクリーンギターとか逆に手の代わりになるような音声入力とかもまぁまぁ現実的に使えるようなレベルになってきたりしてるんでこれはあるしトレーニングが必要なんですけどそういうトレーニングをしつついろいろ改善していく。

この詰めていくとなんかVimとかEmacsの設定とかその辺に結構近い感じなんか個人最適化の設定になっていく感じがします。
大体の音声コマンドにつなげていく感じなんでその設定大好きな人結構Talonをいじってみると楽しいと思います。
Talonの設定ファイルをいじったら自動で反映されるんで、何か入力して音声で入力して音声言ってみたらデバッグできるのでよくできています。

最初の目が衰えてきた場合の対処となるアプリケーション(スクリーンリーダ?)は書いてないんですねまぁそういう人たちが書いてくださいって感じですかね。
